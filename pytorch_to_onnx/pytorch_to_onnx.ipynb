{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "from torch.autograd import Variable\n",
    "from onnx_tf.backend import prepare\n",
    "import onnxruntime as ort\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader as dataloader\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import onnx\n",
    "sys.path.insert(1, 'T:/Haematology FYP/HelperScripts')\n",
    "from HelperFunctions import *\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "device_name = torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True).to(device)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 5).to(device)\n",
    "model_file = \"T:/Haematology FYP/Models/baseline/temp/Greenresnet18_profiling_Green.pt\"\n",
    "check_point = torch.load(model_file)\n",
    "model.load_state_dict(check_point['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the trained model to ONNX\n",
    "input = Variable(torch.randn(64, 3, 160, 160).to(device))\n",
    "model.eval()\n",
    "torch.onnx.export(model, input, \"T:/Haematology FYP/Models/resnet18_new.onnx\", input_names=['input'],output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4563    Batch size: 71\n",
      "Validation samples: 782     Batch size: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zarre\\.conda\\envs\\gpu\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:350: UserWarning: Deprecation warning. This ORT build has ['CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. The next release (ORT 1.10) will require explicitly setting the providers parameter (as opposed to the current behavior of providers getting set/registered by default based on the build flags) when instantiating InferenceSession.For example, onnxruntime.InferenceSession(..., providers=[\"CUDAExecutionProvider\"], ...)\n",
      "  warnings.warn(\"Deprecation warning. This ORT build has {} enabled. \".format(available_providers) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9062)\n"
     ]
    }
   ],
   "source": [
    "classes = ['Basophil','Eosinophil','Lymphocyte','Monocyte','Neutrophil']\n",
    "loader, _ = datamaker('Green','T:/Haematology FYP/Data/WBC_Classification_3172_c/',batch_size=64)\n",
    "img, true = next(iter(loader))\n",
    "img = img.numpy()\n",
    "model = ort.InferenceSession(\"T:/Haematology FYP/Models/resnet18_new.onnx\")\n",
    "input = {'input':img}\n",
    "output = model.run(None,input)[0]\n",
    "preds = torch.from_numpy(output.argmax(axis=1))\n",
    "correct = preds.eq(true.view_as(preds)).sum()\n",
    "acc = correct.float()/preds.shape[0]\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX file\n",
    "model = onnx.load(\"T:/Haematology FYP/Models/resnet18_new.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(model, device='cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4563    Batch size: 4563\n",
      "Validation samples: 782     Batch size: 782\n",
      "tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: T:/Haematology FYP/Models/resnet18_new\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: T:/Haematology FYP/Models/resnet18_new\\assets\n"
     ]
    }
   ],
   "source": [
    "loader, _ = datamaker('Green','T:/Haematology FYP/Data/WBC_Classification_3172_c/',batch_size=1)\n",
    "img, true = next(iter(loader))\n",
    "img = img.numpy()\n",
    "\n",
    "output = tf_rep.run(img)\n",
    "preds = torch.from_numpy(output[0].argmax(axis=1))\n",
    "correct = preds.eq(true.view_as(preds)).sum()\n",
    "acc = correct.float()/preds.shape[0]\n",
    "print(acc)\n",
    "tf_rep.export_graph('T:/Haematology FYP/Models/resnet18_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = tf.saved_model.load('T:/Haematology FYP/Models/resnet18_new')\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('T:/Haematology FYP/Models/resnet18_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_dataset():\n",
    "    \"\"\"Generator function to produce representative dataset for post-training quantization.\"\"\"\n",
    "\n",
    "    # Use a few samples from the training set.\n",
    "    for _ in range(100):\n",
    "        img = iter(loader).next()[0].numpy()\n",
    "        img = [(img.astype(np.float32))]\n",
    "        yield img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = rep_dataset\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11324152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('model.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model in TFLite Interpreter\n",
    "interpreter = tf.lite.Interpreter('model.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = img\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\zarre\\.vscode-server\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "output = tflmodel(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.load_model('T:/Haematology FYP/Models/resnet18_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = new_model.signatures[\"serving_default\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction signature_wrapper(*, input)\n",
      "  Args:\n",
      "    input: float32 Tensor, shape=(64, 3, 160, 160)\n",
      "  Returns:\n",
      "    {'output': <1>}\n",
      "      <1>: float32 Tensor, shape=(64, 5)\n"
     ]
    }
   ],
   "source": [
    "print(infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54bd428ae3c8c7da62786e7f4f99fce11270d7e2d105794f22af38386a63a9cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tf_gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
